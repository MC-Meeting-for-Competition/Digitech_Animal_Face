{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d6392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'fox', 'rabbit']\n",
      "이미지 배치 shape: torch.Size([2, 3, 64, 64])\n",
      "레이블: tensor([2, 0])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"dataset\")\n",
    "train_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"이미지 배치 shape:\", images.shape)\n",
    "print(\"레이블:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc29308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultipleClassificationModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        모델의 초기화 함수, 모델에 사용할 각 계층을 정의\n",
    "        num_classes : 분류할 클래스의 수\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        #  첫 번째 Convolution Block\n",
    "        # Conv2d :  이미지에서 특성을 추출하는 층\n",
    "        # ( 입력 채널 : 3, 출력 채널 : 32, 커널 크기 : 3 x 3 )  / 커널(= 필터, 마스크) : 이미지로부터 원하는 특징만 추출하는 것\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # RGB 이미지 ( 채널 3 ) 을 입력받고, 32개의 특성 맵을 추출\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32 개 특성 맵을 입력받고, 64개로 확장\n",
    "        self.pool = nn.MaxPool2d(2, 2) # Max Pooling : 특성 맵의 크기를 절반으로 줄임 ( => 계산량 감소 )\n",
    "        \n",
    "        # 두 번째 Convolution Block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 64개의 특성 맵을 받아 128개로 확장\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # 128개의 특성 맵을 받아 256개로 확장\n",
    "        \n",
    "        # Fully Connected Layers ( FC ) : 마지막에 나온 특성 맵을 1차원 벡터로 펼쳐서 분류 작업을 시행\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 1024) # 마지막 특성 맵을 1024개의 뉴런으로 변환\n",
    "        self.fc2 = nn.Linear(1024, num_classes) # 1024개의 뉴런을 받아 최종 클래스 개수에 맞는 출력값을 생성'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        입력 데이터 x를 모델을 통해 순차적으로 전달하며 예측을 생성\n",
    "        \"\"\"\n",
    "        \n",
    "        #  첫 번째 Convolution Block\n",
    "        x = F.relu(self.conv1(x)) # 첫 번째 Conv2d + ReLU 활성화 함수\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 두 번째 Conv2d + ReLU + Max pooling\n",
    "        \n",
    "        x = F.relu(self.conv3(x)) # 세 번째 Conv2d + ReLU 활성화 함수\n",
    "        x = self.pool(F.relu(self.conv4(x))) # 네 번째 Conv2d + ReLU + Max pooling\n",
    "        \n",
    "        # 전역 평균 풀링 (  Global Average Pooling ) : 특성 맵을 1차원 벡터로 평탄화\n",
    "        x = x.view(-1, 256 * 16 * 16) # 특성 맵을 1차원 벡터로 펼침\n",
    "        \n",
    "        # Fully Connected Layers ( FC ) : 최종 분류 결과를 출력\n",
    "        x = F.relu(self.fc1(x)) # 첫 번째 FC + ReLU 활성화 함수\n",
    "        x = self.fc2(x) # 두 번째 FC : 최송 클래스에 대한 예측 결과\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c54a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss : 1.5805, Accuracy: 25.00%\n",
      "Epoch [2/20], Loss : 1.4133, Accuracy: 20.00%\n",
      "Epoch [3/20], Loss : 1.3869, Accuracy: 25.00%\n",
      "Epoch [4/20], Loss : 1.3869, Accuracy: 25.00%\n",
      "Epoch [5/20], Loss : 1.3865, Accuracy: 25.00%\n",
      "Epoch [6/20], Loss : 1.3871, Accuracy: 30.00%\n",
      "Epoch [7/20], Loss : 1.3862, Accuracy: 25.00%\n",
      "Epoch [8/20], Loss : 1.3902, Accuracy: 27.50%\n",
      "Epoch [9/20], Loss : 1.3861, Accuracy: 27.50%\n",
      "Epoch [10/20], Loss : 1.4734, Accuracy: 35.00%\n",
      "Epoch [11/20], Loss : 1.3676, Accuracy: 20.00%\n",
      "Epoch [12/20], Loss : 1.2968, Accuracy: 27.50%\n",
      "Epoch [13/20], Loss : 1.3810, Accuracy: 55.00%\n",
      "Epoch [14/20], Loss : 1.0087, Accuracy: 67.50%\n",
      "Epoch [15/20], Loss : 1.0567, Accuracy: 70.00%\n",
      "Epoch [16/20], Loss : 0.5389, Accuracy: 77.50%\n",
      "Epoch [17/20], Loss : 0.4590, Accuracy: 82.50%\n",
      "Epoch [18/20], Loss : 0.8881, Accuracy: 85.00%\n",
      "Epoch [19/20], Loss : 0.6935, Accuracy: 72.50%\n",
      "Epoch [20/20], Loss : 0.2431, Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = MultipleClassificationModel(num_classes=num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss : {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct/total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c41e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(), \"model/animal_face.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_animal_face",
   "language": "python",
   "name": "py312_animal_face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
